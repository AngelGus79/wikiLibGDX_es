# 9.2 Mouse, Touch y Teclado

Los principales dispositivos de entrada que libgdx soporta son el mouse en el escritorio/navegador, pantallas táctiles en Android y teclados. Veamos cómo libgdx se abstrae de estos.

## Teclado

El teclado genera señales de entrada del usuario mediante la generación de eventos al pulsar y soltar una tecla. Cada evento lleva consigo un código clave que identifica la tecla que se ha pulsado/soltado. Estos códigos de teclado difieren de una plataforma a otra. Libgdx trata de ocultar este hecho al proporcionar su propia tabla de códigos clave, consulte la clase [Keys](http://libgdx.badlogicgames.com/nightlies/docs/api/com/badlogic/gdx/Input.Keys.html) [(fuente)](https://github.com/libgdx/libgdx/blob/master/gdx/src/com/badlogic/gdx/Input.java#L63). Puede consultar qué teclas están siendo presionadas por medio de [polling](09.2.1.md).

Solo los códigos de las teclas no nos dan la información acerca de qué personaje el usuario realmente uso. Esta información a menudo se deriva del estado de varias teclas, por ejemplo, el carácter 'A' se genera mediante las teclas 'a' y 'shift' al ser pulsadas simultáneamente. En general, conocer que caracteres del teclado estan presionados (las teclas que están abajo) no es trivial. Afortunadamente, el sistema operativo por lo general tiene un medio para conectar un detector de eventos que no sólo informa de los eventos de código de tecla (tecla presionada/tecla liberada), sino también los caracteres. Libgdx utiliza este mecanismo bajo el capó para ofrecerle la información de caracteres. Consulte [Manejo de eventos](09.2.2.md).

## Mouse y Touch

La entrada por medio del Mouse y el Touch le permiten al usuario apuntar las cosas en la pantalla. Ambos mecanismos de entrada nos comunican la ubicación de la interacción como coordenadas 2D respecto a la esquina superior izquierda de la pantalla, con el eje x positivo apuntando a la derecha y el eje y apuntando hacia abajo.

La entrada del Mouse viene con información adicional, al saber qué botón se presionó. La mayoría de los ratones presentan un botón izquierdo y un botón derecho, así como un botón central. Además, a menudo hay una rueda de desplazamiento que se puede utilizar para el zoom o el desplazamiento en muchas aplicaciones.

La entrada táctil no tiene la noción de botones y se complica por el hecho de que múltiples dedos pueden ser rastreados en función del hardware. Los teléfonos Android de primera generación sólo admiten un solo toque. Comenzando con teléfonos como el Motorola Droid, el multi-touch se convirtió en una característica estándar en la mayoría de los teléfonos Android.

Tenga en cuenta que toque puede ser implementado de manera muy diferente en diferentes dispositivos. Esto puede afectar la manera en que se especifican y se liberan los índices de puntero y cuando se disparan los eventos táctiles. Asegúrese de probar el esquema de control en tantos dispositivos como sea posible. También hay muchas aplicaciones de test de entrada disponibles en el Google Play que pueden ayudar a determinar cómo un dispositivo en particular nos informa del contacto y nos ayuda en el diseño de un esquema de control que funciona mejor a través de una gama de dispositivos.

Libgdx nos abstrae del manejo unificado del mouse y touch. Nosotros vemos la entrada del mouse como una forma especializada de entrada táctil. Sólo se hace seguimiento a un dedo, y además de las coordenadas también informamos que botones se pulsan. Para la entrada táctil soportamos el seguimiento de varios dedos (punteros) y reportamos el botón izquierdo mouse ratón para todos los eventos.

Tenga en cuenta que el sistema de coordenadas en Android es relativo al modo horizontal o vertical, dependiendo de la configuración de su aplicación.

Mouse y el Touch bien pueden ser [polled](09.2.1.md) o se procesan a través de el [Manejo de Eventos](09.2.2.md)

## Enlaces

- [Indice](preface.md)
- Sección anterior: [Configuración y consultas](09.1.md)
- Siguiente sección: [Polling](09.2.1.md)